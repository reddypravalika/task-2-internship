import numpy as np
import pandas as pd
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.metrics import silhouette_score, davies_bouldin_score
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
import seaborn as sns

# Load and preprocess the dataset
data = pd.read_csv('library_dataset.csv')

# Assuming 'data' is your preprocessed dataset

# K-means Clustering
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans_labels = kmeans.fit_predict(data)

# Hierarchical Clustering
hierarchical = AgglomerativeClustering(n_clusters=3)
hierarchical_labels = hierarchical.fit_predict(data)

# Evaluate the Clustering
silhouette_kmeans = silhouette_score(data, kmeans_labels)
davies_bouldin_kmeans = davies_bouldin_score(data, kmeans_labels)

silhouette_hierarchical = silhouette_score(data, hierarchical_labels)
davies_bouldin_hierarchical = davies_bouldin_score(data, hierarchical_labels)

print(f"K-Means Silhouette Score: {silhouette_kmeans}")
print(f"K-Means Davies-Bouldin Index: {davies_bouldin_kmeans}")
print(f"Hierarchical Silhouette Score: {silhouette_hierarchical}")
print(f"Hierarchical Davies-Bouldin Index: {davies_bouldin_hierarchical}")

# Visualization using PCA for 2D plotting
pca = PCA(2)
data_pca = pca.fit_transform(data)

# Scatter plot for K-means
plt.figure(figsize=(10,5))
plt.subplot(1, 2, 1)
sns.scatterplot(x=data_pca[:,0], y=data_pca[:,1], hue=kmeans_labels, palette='viridis')
plt.title("K-Means Clustering")

# Scatter plot for Hierarchical Clustering
plt.subplot(1, 2, 2)
sns.scatterplot(x=data_pca[:,0], y=data_pca[:,1], hue=hierarchical_labels, palette='viridis')
plt.title("Hierarchical Clustering")

plt.show()
